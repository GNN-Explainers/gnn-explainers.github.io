---
layout: default
title: "GNN Explainers 2.0: User-centric and Data-driven Insights"
---

[//]: # (# GNN Explainers 2.0)

<section class="speakers-section" markdown="1">
## Speakers

<div class="speakers-grid">
  <div class="speaker">
    <img src="assets/speakers/khan.jpg" alt="Speaker 6 Name" class="speaker-photo">
    <h3><a href="https://www.cs.bgsu.edu/arijitk" target="_blank">Arijit Khan</a></h3>
    <p>Bowling Green State University</p>
  </div>
  <div class="speaker">
    <img src="assets/speakers/ke.jpg" alt="Speaker 6 Name" class="speaker-photo">
    <h3><a href="https://person.zju.edu.cn/en/kexiangyu" target="_blank">Xiangyu Ke</a></h3>
    <p>Zhejiang University</p>
  </div>
  <div class="speaker">
    <img src="assets/speakers/wu.jpg" alt="Speaker 6 Name" class="speaker-photo">
    <h3><a href="https://yinghwu.github.io" target="_blank">Yinghui Wu</a></h3>
    <p>Case Western Reserve<br> University</p>
  </div>
  <div class="speaker">
    <img src="assets/speakers/bonchi.jpg" alt="Speaker 6 Name" class="speaker-photo">
    <h3><a href="https://www.francescobonchi.com" target="_blank">Francesco Bonchi</a></h3>
    <p>CENTAI Institute</p>
  </div>
</div>
</section>

---

## Abstract

<div class="abstract-section">

<p>
Graph neural networks (GNNs) are deep learning models designed
for graph-structured data that have achieved strong results across
domains–social networks, knowledge graphs, bioinformatics, transportation, 
World Wide Web, and finance–on tasks such as node
and graph classification, link prediction, entity resolution, question 
answering, recommendation, and fraud detection. Explaining
the decisions of high-performing, yet “black-box” GNNs remains
both challenging and essential. The initial five years have produced
tremendous progress with many GNN explainers (e.g., GNNExplainer, 
PGExplainer, SubgraphX, PGMExplainer, GraphLime, GCF-Explainer, CF2, GNN-LRP) 
that identify the influential nodes, edges,
subgraphs, and features aiming to explain the output of GNNs.
</p>

<p>
We refer to those works as GNN Explainers 1.0, since they provide 
one-time, final-output explanations and are focused on narrow
tasks like node or graph classification, which limits their usefulness 
for broader, user-centered needs. Practical debugging and
accountability require robust, multi-faceted, and GNN’s layer-wise
provenance so that data scientists can trace how inputs transform
through layers and locate where errors occur. Non-technical stakeholders 
need explanations that are accessible, configurable, and
queryable through familiar interfaces–structured queries, ad-hoc
instructions, counterfactual evidence, or natural language–so both
experts and non-experts can interactively explore model behavior.
</p>

<p>
This tutorial surveys latest advances in user-centered GNN explanations 
that shift focus from merely explaining model outputs
to producing actionable, end-user-facing explanations. We show
how data mining principles can improve comprehension, usability,
and trust, and outline practical strategies for creating configurable,
interpretable explanations tailored to diverse stakeholders. We refer
to this paradigm as GNN Explainers 2.0. We demonstrate key works
under this paradigm, summarize open challenges, and highlight
opportunities for the web and data mining community.
</p>

</div>

---

## Schedule

### Part 1: Introduction. (00:00 - 00:30)

- **1.1**&nbsp;&nbsp;GNNs and Applications
- **1.2**&nbsp;&nbsp;XAI for GNNs
- **1.1** GNNs and Applications
- **1.2** XAI for GNNs

### Part 2: GNN Explainers Categorization. (00:30 - 00:45)

### Part 3: User-centric XAI. (00:45 - 01:00)

### Part 4: User-centric and Data-driven XAI Methods for GNNs. (01:00 - 02:30)

- **4.1**&nbsp;&nbsp;Pattern Mining and Concept Hierarchies
- **4.2**&nbsp;&nbsp;Counterfactual Explanations
- **4.3**&nbsp;&nbsp;Explanation by Examples and Rules
- **4.4**&nbsp;&nbsp;Natural Language Explanations
- **4.5**&nbsp;&nbsp;Declarative Explanatory Queries
- **4.6**&nbsp;&nbsp;Robust Explanations
- **4.7**&nbsp;&nbsp;Multi-criteria Explanations
- **4.8**&nbsp;&nbsp;Efficiency and Interactiveness
- **4.9**&nbsp;&nbsp;XAI beyond Classification

### Part 5: Future Directions (02:30 - 03:00)
